{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7e473b-ec91-4707-8dc3-0b80ea2c9498",
   "metadata": {},
   "source": [
    "# Loading, Displaying, Resizing, and Creating Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b9fa9-c356-461e-afdd-654eb54db14e",
   "metadata": {},
   "source": [
    "## Loading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105ef4a-27ec-4277-9875-5cb9d95a16c0",
   "metadata": {},
   "source": [
    "When you load image in openCV it becomes a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d17774-71d6-4d54-9ddb-5f12bb5ac2bb",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "| Function          | Description                                      | Syntax                                           |\n",
    "|-------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| `cv2.imread`      | Reads an image from a file.                      | `cv2.imread('path/to/your/image.jpg')`           |\n",
    "| `cv2.imshow`      | Displays an image in a window.                   | `cv2.imshow('Window Name', image)`               |\n",
    "| `cv2.waitKey`     | Waits for a key event indefinitely or for a delay. | `cv2.waitKey()`                                  |\n",
    "| `cv2.destroyAllWindows` | Closes all the windows opened by OpenCV.       | `cv2.destroyAllWindows()`                        |\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "| Argument          | Description                                      | Possible Values                                  | Syntax                                           |\n",
    "|-------------------|--------------------------------------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| `filename`        | Name of the file to be read.                     | `path/to/your/image.jpg`                         | `cv2.imread('filename')`                         |\n",
    "| `flags`           | Specifies the color type of a loaded image.      | `cv2.IMREAD_COLOR`, `cv2.IMREAD_GRAYSCALE`, `cv2.IMREAD_UNCHANGED` | `cv2.imread('filename', flags)`                  |\n",
    "| `winname`         | Name of the window in which the image is displayed. | Any string                                       | `cv2.imshow('winname', image)`                   |\n",
    "| `image`           | The image matrix to be displayed.                | `image`                                          | `cv2.imshow('winname', image)`                   |\n",
    "| `delay`           | Time in milliseconds.                            | `0`, any positive integer                        | `cv2.waitKey(delay)`                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5adfef34-a8bc-4a7c-bfd2-368c9d0c14a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 112, 109, ...,  69,  73,  81],\n",
       "       [131, 102, 100, ...,  65,  68,  75],\n",
       "       [118,  93,  93, ...,  67,  69,  76],\n",
       "       ...,\n",
       "       [247, 201, 204, ..., 243, 237, 255],\n",
       "       [239, 195, 202, ..., 241, 235, 253],\n",
       "       [241, 197, 201, ..., 241, 236, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "feynman = cv2.imread(\"assets\\\\feynman.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "feynman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d681010-3eca-4b55-8c4b-37278ad34f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feynman.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a6bb8-fca5-45ef-801b-d2dd014a5134",
   "metadata": {},
   "source": [
    "## Displaying an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "128cdf24-2991-4bba-9140-b3896086d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Feynman\", feynman)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf26249-1ff1-49bd-8551-588d31174ad1",
   "metadata": {},
   "source": [
    "## Resizing an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e02b9077-00b7-4f6c-bbb4-a278c7619fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizedFeynman = cv2.resize(feynman, (500, 500))\n",
    "cv2.imshow(\"Feynman\", resizedFeynman)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe491c2-15cc-4ba7-883b-7a364d9aca5d",
   "metadata": {},
   "source": [
    "## Creating an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c8630-d6ed-42d4-b098-c1fb707558c2",
   "metadata": {},
   "source": [
    "This is the inverse of loading an image, by loading an image, you have an image and then convert it to matrix now you have a matrix and you want to convert it to image so let's say we have the matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e18e7a1b-d125-4d0e-b01f-5ab361b706e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 141, 130, ...,  77,  80,  81],\n",
       "       [137, 135, 124, ...,  75,  77,  78],\n",
       "       [129, 127, 116, ...,  72,  75,  75],\n",
       "       ...,\n",
       "       [240, 237, 221, ..., 245, 252, 253],\n",
       "       [240, 237, 221, ..., 246, 253, 254],\n",
       "       [241, 238, 222, ..., 247, 254, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFeynman = cv2.resize(feynman, (feynman.shape[0] * 2, feynman.shape[1] * 2))\n",
    "newFeynman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a18f8b20-2b23-4507-9166-9b7d644335af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 141, 131, ...,  77,  81,  81],\n",
       "       [137, 135, 125, ...,  74,  77,  77],\n",
       "       [129, 127, 117, ...,  72,  75,  75],\n",
       "       ...,\n",
       "       [241, 238, 222, ..., 245, 252, 253],\n",
       "       [239, 237, 221, ..., 246, 253, 254],\n",
       "       [241, 238, 223, ..., 247, 254, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFeynmanImg = cv2.imwrite(\"FeynmanResized.jpg\", newFeynman)\n",
    "newFeynmanImgMat = cv2.imread(\"FeynmanResized.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "newFeynmanImgMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eae89678-e159-4f0c-a06b-1ab21aa87e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"FeynmanResized\", newFeynmanImgMat)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398befbf-9784-4680-bc33-849c7148db5c",
   "metadata": {},
   "source": [
    "## Detecting Faces in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1907e1-e9e9-423b-9bba-cb7eaec32945",
   "metadata": {},
   "source": [
    "**Arguments**  \n",
    "\n",
    "| Arguments      | Description                                      | Possible Values | Syntax |\n",
    "|---------------|--------------------------------------------------|----------------|--------|\n",
    "| `scaleFactor` | Controls how much the image size is reduced at each image scale. | `value` | `detectMultiScale(scaleFactor = )` |\n",
    "| `minNeighbors` | Specifies how many neighbors a rectangle should have to retain it. | `value` | `detectMultiScale(minNeighbors = )` |\n",
    "| `minSize`     | Minimum possible object size. Objects smaller than this are ignored. | `(width, height)` | `detectMultiScale(minSize = )` |\n",
    "| `maxSize`     | Maximum possible object size. Objects larger than this are ignored. | `(width, height)` | `detectMultiScale(maxSize = )` |\n",
    "| `flags`       | Parameter with different modes for detection. | `cv2.CASCADE_SCALE_IMAGE` (commonly used) | `detectMultiScale(flags = )` |\n",
    "| `color`       | Color of the rectangle outline. | `(B, G, R)` or `color_name` | `rectangle(img, pt1, pt2, color = )` |\n",
    "| `thickness`   | Thickness of the rectangle border. | `value` | `rectangle(img, pt1, pt2, color, thickness = )` |\n",
    "| `lineType`    | Type of line used for the rectangle. | `cv2.LINE_AA`, `cv2.LINE_4`, `cv2.LINE_8` | `rectangle(img, pt1, pt2, color, thickness, lineType = )` |\n",
    "\n",
    "\n",
    "**Functions**  \n",
    "\n",
    "| Functions              | Description                                      | Syntax |\n",
    "|------------------------|--------------------------------------------------|--------|\n",
    "| `CascadeClassifier`    | Loads a pre-trained classifier for object detection. | `cv2.CascadeClassifier('path')` |\n",
    "| `detectMultiScale`     | Detects objects in an image. Used for face detection. | `classifier.detectMultiScale(img, scaleFactor=, minNeighbors=, minSize=, maxSize=, flags=)` |\n",
    "| `rectangle`           | Draws a rectangle around detected objects. | `cv2.rectangle(img, pt1, pt2, color, thickness, lineType)` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "886076df-9439-4b53-9a66-18ce9d6045a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152,  84, 384, 384]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cv2 import CascadeClassifier\n",
    "\n",
    "img = cv2.imread(\"assets\\\\photo.jpg\")\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# now that we have the image we can now instantiate our model that detects faces from photos\n",
    "face_detector = CascadeClassifier(\"assets\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# this will return a coordinate (x, y, w, h)\n",
    "face = face_detector.detectMultiScale(imgGray)\n",
    "\n",
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7e85253-6b62-489b-a1ca-b61a6ca0bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have coordinates for faces, we can now draw a rectangle to it\n",
    "for (x,y,w,h) in face:\n",
    "    imgRec = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2, cv2.LINE_AA)\n",
    "    \n",
    "cv2.imshow(\"Face Detection\", imgRec)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1076ccb5-b1d4-4772-9d7b-a3f94aacfaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46, 220, 111, 111]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsImg = cv2.imread(\"assets\\\\news.jpg\")\n",
    "newsImgGray = cv2.cvtColor(newsImg, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_detector.detectMultiScale(newsImgGray)\n",
    "\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13527919-63c8-49b9-901d-e0bafddd4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, w, h in faces:\n",
    "    recNews =  cv2.rectangle(newsImg, (x, y), (x + w, y + h), (255, 0 , 0), 2, cv2.LINE_8)\n",
    "\n",
    "cv2.imshow(\"Face Detection\", recNews)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "403ee8c5-7b6a-422f-8a6e-93b6c545337b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[536, 132,  73,  73],\n",
       "       [  5, 127,  77,  77],\n",
       "       [455, 160,  77,  77],\n",
       "       [289, 166,  72,  72],\n",
       "       [170, 182,  74,  74],\n",
       "       [381, 182,  67,  67],\n",
       "       [ 92, 182,  80,  80],\n",
       "       [ 38, 256,  77,  77],\n",
       "       [226, 280,  72,  72],\n",
       "       [284, 264,  80,  80],\n",
       "       [397, 289,  72,  72],\n",
       "       [370,  83,  76,  76],\n",
       "       [115,  87,  79,  79],\n",
       "       [228,  89,  78,  78]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filipinoImg = cv2.imread(\"assets\\\\Filipino.jpg\")\n",
    "filipinoImgGray = cv2.cvtColor(filipinoImg, cv2.COLOR_BGR2GRAY)\n",
    "filipinoFaces = face_detector.detectMultiScale(filipinoImgGray)\n",
    "\n",
    "filipinoFaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "821d9b92-47d3-4cd5-ad1b-a9359f06aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, w, h in filipinoFaces:\n",
    "    recFilipino =  cv2.rectangle(filipinoImg, (x, y), (x + w, y + h), (255, 0 , 0), 2)\n",
    "\n",
    "# recFilipino =  cv2.rectangle(filipinoImg, (filipinoFaces[3][0], filipinoFaces[3][1]), (filipinoFaces[3][0] + filipinoFaces[3][2],\n",
    "#                                                                                        filipinoFaces[3][1] + filipinoFaces[3][3]), (255, 0 , 0), 2)\n",
    "\n",
    "cv2.imshow(\"Face Detection\", recFilipino)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da382c-d50b-4e72-8676-51b14d49d162",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4a942d6-e0a5-44b4-b7f0-a4087053af3a",
   "metadata": {},
   "source": [
    "## Capturing Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f470a-e64c-4187-b3a9-b780b4aeceff",
   "metadata": {},
   "source": [
    "**Arguments**  \n",
    "\n",
    "| Arguments      | Description                                      | Possible Values | Syntax |\n",
    "|---------------|--------------------------------------------------|----------------|--------|\n",
    "| `deviceIndex` | Index of the camera to be used. | `0` (default webcam), `1, 2, ...` for external cameras | `VideoCapture(deviceIndex = )` |\n",
    "| `filename`    | Name of the output video file. | `\"filename.format\"` | `VideoWriter(filename = )` |\n",
    "| `fourcc`      | Codec used to compress the video. | `cv2.VideoWriter_fourcc(*'XVID')`, `cv2.VideoWriter_fourcc(*'MJPG')`, etc. | `VideoWriter(filename, fourcc = )` |\n",
    "| `fps`        | Frames per second of the output video. | `value` | `VideoWriter(filename, fourcc, fps = )` |\n",
    "| `frameSize`   | Size of the output video frames. | `(width, height)` | `VideoWriter(filename, fourcc, fps, frameSize = )` |\n",
    "| `isColor`     | Flag to specify if the output video is in color. | `True` (color), `False` (grayscale) | `VideoWriter(filename, fourcc, fps, frameSize, isColor = )` |\n",
    "| `propId`      | Property identifier to get or set camera properties. | `cv2.CAP_PROP_FRAME_WIDTH`, `cv2.CAP_PROP_FRAME_HEIGHT`, etc. | `VideoCapture.get(propId = )` / `VideoCapture.set(propId, value)` |\n",
    "\n",
    "\n",
    "\n",
    "**Functions**  \n",
    "\n",
    "| Functions              | Description                                      | Syntax |\n",
    "|------------------------|--------------------------------------------------|--------|\n",
    "| `VideoCapture`        | Captures video from a camera or file. | `cv2.VideoCapture(deviceIndex)` |\n",
    "| `read`               | Reads the next frame from the video capture. | `object.read()` |\n",
    "| `imwrite`            | Saves a frame as an image file. | `cv2.imwrite('filename.format', frame)` |\n",
    "| `VideoWriter`        | Saves frames as a video file. | `cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor)` |\n",
    "| `waitKey`            | Waits for a key press for a given time in milliseconds. | `cv2.waitKey(delay)` |\n",
    "| `destroyAllWindows`  | Closes all OpenCV windows. | `cv2.destroyAllWindows()` |\n",
    "| `release`           | Releases the video capture or writer object. | `capture.release()` / `writer.release()` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c02d80-f8ea-4d29-8acd-5d77d91bddec",
   "metadata": {},
   "source": [
    "Okay so what you want to do is get the frames and then stitch them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a5acdd7-842f-4e7a-a0ee-45bc5fbf393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Now, we have an object to use to be able to capture videos\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "check, frame = video.read()\n",
    "\n",
    "if check:\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    video.release()\n",
    "    cv2.waitKey(5000)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"The camera did not work\")\n",
    "\n",
    "# got the face detector\n",
    "face_detector = cv2.CascadeClassifier('assets\\\\haarcascade_frontalface_default.xml')\n",
    "frameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "face_coordinates = face_detector.detectMultiScale(frameGray, minNeighbors = 5, scaleFactor = 1.05)\n",
    "\n",
    "for x, y, w, h in face_coordinates:\n",
    "    image = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), thickness = 5)\n",
    "cv2.imshow(\"face detection\", image)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c922bac-85d7-490b-8e4d-0dd1aadc6e7f",
   "metadata": {},
   "source": [
    "### Showing an Actual Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6dad07-b709-43ff-af11-7c576a9ba1ab",
   "metadata": {},
   "source": [
    "- We need to use a while loop so we can get the frames that we need.\n",
    "- Inside this while loop we get the frame and show it and use waitkey\n",
    "- release the video\n",
    "- destroy the windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab99bf-37ff-4fa0-bb2c-8bfba11c2782",
   "metadata": {},
   "source": [
    "```python\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    check, frame = video.read()\n",
    "    if check:\n",
    "        face_detection = cv2.CascadeClassifier(\"assets\\\\haarcascade_frontalface_default.xml\")\n",
    "        face_coordinates = face_detection.detectMultiScale(image=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        \n",
    "        for x, y, w, h in face_coordinates:\n",
    "            image = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 248, 252), 3)\n",
    "\n",
    "        cv2.imshow(\"Face_detection\", image)\n",
    "        key = cv2.waitKey(1000)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8ae28-001a-4b08-8e2c-f8130e38de2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
