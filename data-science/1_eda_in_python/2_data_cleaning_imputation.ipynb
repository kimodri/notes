{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e823339d-e5d9-4d4a-8239-2c9a3ac19011",
   "metadata": {},
   "source": [
    "# Data Cleaning and Imputation\n",
    "06/29/2025\n",
    "\n",
    "We use the salaries dataframe for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bab54d-5ab3-49f9-bcbc-afdf1f841739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Working_Year</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Employee_Location</th>\n",
       "      <th>Company_Size</th>\n",
       "      <th>Remote_Working_Ratio</th>\n",
       "      <th>Salary_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid</td>\n",
       "      <td>FT</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>76227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>FT</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>248257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>FT</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>104100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>Mid</td>\n",
       "      <td>FT</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>19097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>FT</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>50</td>\n",
       "      <td>143225.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Working_Year                 Designation Experience Employment_Status  \\\n",
       "0          2020              Data Scientist        Mid                FT   \n",
       "1          2020  Machine Learning Scientist     Senior                FT   \n",
       "2          2020           Big Data Engineer     Senior                FT   \n",
       "3          2020        Product Data Analyst        Mid                FT   \n",
       "4          2020   Machine Learning Engineer     Senior                FT   \n",
       "\n",
       "  Employee_Location Company_Size  Remote_Working_Ratio  Salary_USD  \n",
       "0                DE            L                     0     76227.0  \n",
       "1                JP            S                     0    248257.0  \n",
       "2                GB            M                    50    104100.0  \n",
       "3                HN            S                     0     19097.0  \n",
       "4                US            L                    50    143225.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_salaries = pd.read_csv('datasets/salaries.csv')\n",
    "df_salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeba67d-b7e2-4206-b9b8-af9199c1eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience\n",
       "Entry         58859.102273\n",
       "Executive    190386.230769\n",
       "Mid           84021.652582\n",
       "Senior       132356.528571\n",
       "Name: Salary_USD, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salaries.groupby('Experience')['Salary_USD'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785276cd-b6c1-4bb7-a037-26a2aef0bf72",
   "metadata": {},
   "source": [
    "## Addressing Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be23420-b3f0-4c9c-a318-75c348d92fbc",
   "metadata": {},
   "source": [
    "### Checking For Missing Values\n",
    "\n",
    "- We chain: `.isna()` and `.sum()`\n",
    "\n",
    "Example:\n",
    "`df.isna().sum()`\n",
    "\n",
    "Always ask yourself when did I get missing values as it might tell something about the data, **by doing that you can identify what kind of missing data they are**\n",
    "\n",
    "What you can do then is **isolate** missing and non-missing and ddo `.describe()` on each\n",
    "\n",
    "- `missing complete at random`\n",
    "- `missing at random`\n",
    "- `missing not at random`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3992a2a-ea9c-49cf-99a2-3b4779dd88e8",
   "metadata": {},
   "source": [
    "### Strategies when Dealing w/ Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ccd1f-95c8-43db-a606-cc153330c760",
   "metadata": {},
   "source": [
    "- Drop missing values\n",
    "  - We drop them if the total values amount to 5% or less of total values\n",
    "- Impute them (mean, median, or mode)\n",
    "  - This depends on distribution and context\n",
    "- Impute by sub-group\n",
    "  - Well different subgroups have different summary statistics so if you're gonna impute them better use the most fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81859a6b-0306-4b9c-a7ec-82ba5c5a867c",
   "metadata": {},
   "source": [
    "**Dropping Missing Values:**\n",
    "1. We calculate the threshold (5% of the dataset)\n",
    "  ```python\n",
    "  threshold = len(df) * 0.05\n",
    "  ```\n",
    "2. Determine the columns that contain missing values less than the threshold\n",
    "   ```python\n",
    "   cols_to_drop = df.columns[df.isna().sum() <= threshold]\n",
    "   ```\n",
    "3. Drop the missing values\n",
    "   ```python\n",
    "    df.dropna(subset = cols_to_drop, inplace = True)\n",
    "   ```\n",
    "   - According to the documentation subset is a label usually columns if you are dropping rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a9665-c1e1-4242-b68f-bd5618c8fb75",
   "metadata": {},
   "source": [
    "**Imputing:**\n",
    "- This can be done with sklearn as well\n",
    "\n",
    "1. Find columns with missing values\n",
    "   ```python\n",
    "    cols_with_na = df.columns[df.isna().sum() > 0]\n",
    "   ```\n",
    "2. Loop through the columns and passing the value\n",
    "   ```python\n",
    "   for col in cols_with_na:\n",
    "       df[col].fillna(df[col].mode()[0])\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ddc6d-05ff-4053-8554-01ed09b349c5",
   "metadata": {},
   "source": [
    "**Imputing by Subgroups:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a1d695-c318-4889-a256-148c4e6bf197",
   "metadata": {},
   "source": [
    "1. You get the aggregate function that you want to use for each group\n",
    "   ```python\n",
    "    mean_series = df.groupby('category')['numerical_col'].mean()\n",
    "   ```\n",
    "2. You transform the series into a dictionary\n",
    "   ```python\n",
    "    mean_dict = mean_series.to_dict()\n",
    "   ```\n",
    "3. Fill the subgroups using `.fillna()`\n",
    "   ```python\n",
    "    df['numerical_col'] = df['numerical_col'].fillna(df['category'].map(mean_dict))\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
