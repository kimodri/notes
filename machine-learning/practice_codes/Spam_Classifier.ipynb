{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3cf440-e34b-4b30-9cb3-cc8f2a22b291",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5400a-7d62-43e4-ad80-03998dde37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c4a22-edb5-4f83-b02a-c353c6294cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.listdir(\"Assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64c557-8db7-4123-abdb-ae79570d4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Assets\\\\spam.csv\",encoding='ISO-8859-1')\n",
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "df.columns = ['target', 'document']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6e9a9-e79c-473e-b136-5a5184c05096",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, y = \"target\", kind = \"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5a50-2b56-4cba-b1be-01f91f140002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spam: \", len(df[df['target'] == 'spam']))\n",
    "print(\"Ham: \", len(df[df['target'] == 'ham']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669cfc1-3ea0-4c39-9e12-187f95dacaf0",
   "metadata": {},
   "source": [
    "**We have a problem in here because spam messages are underrepresented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae1c8a-5544-4f40-ae58-906a11093051",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d65ea9-3f6b-439e-a88a-0b62c4b8817c",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4a917-76bc-4edc-bf52-e6273e6607e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Creating an instance of the class\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "corpus = []\n",
    "# clean the dataset\n",
    "for i in range(len(df)):\n",
    "    doc = df.iloc[i, 1].lower()\n",
    "    doc = re.sub('[^a-zA-Z]', ' ', doc)\n",
    "    doc = doc.split()\n",
    "\n",
    "    word = [lemmatizer.lemmatize(word) for word in doc if word not in set(stopwords.words(\"english\"))]\n",
    "    corpus.append(' '.join(word))\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053a100-890a-4277-ba91-29f3585bbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "X = tv.fit_transform(corpus).toarray()\n",
    "y = pd.get_dummies(df['target'], drop_first = True).values.reshape(-1)\n",
    "\n",
    "print(X[0:5])\n",
    "print(X.shape)\n",
    "print(y[0:5])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e3531-f51b-4638-84b2-2907cc68c930",
   "metadata": {},
   "source": [
    "### Preprocessing the Data and Finding the Best Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d905b91-089b-45ae-a166-b9aa494f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Import the preprocessing tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\"knn\": KNeighborsClassifier(), \"logreg\": LogisticRegression(), \"DTC\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits = 6, random_state = 42, shuffle = True)\n",
    "    results.append(cross_val_score(model, X_train_scaled, y_train, cv = kf))\n",
    "\n",
    "plt.boxplot(results, labels = models.keys())\n",
    "plt.show()\n",
    "print(results)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    print(name + \": \" + str(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42acc45-441d-439f-b2db-63556792f9e4",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning the Logistic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76f282-8c24-46e2-b1a4-43b8d789f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "params = [{'penalty':['l1','l2','elasticnet', 'None'],\n",
    "    'C' : np.logspace(-4,4,20),\n",
    "    'solver': ['lbfgs','newton-cg','liblinear','sag','saga']}]\n",
    "\n",
    "cv = RandomizedSearchCV(logreg, params, cv = kf, n_iter = 2)\n",
    "cv.fit(X_train_scaled, y_train)\n",
    "print(cv.best_params_, cv.bes_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b054a-43a4-4a73-8e77-d813b05928b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# y_pred = \n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# disp =  ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490e88c-dd45-4df6-b014-0c4bf55ea585",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
