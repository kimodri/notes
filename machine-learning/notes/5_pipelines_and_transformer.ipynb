{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9192b8b0-ba44-44c6-9dc8-e36997fa026e",
   "metadata": {},
   "source": [
    "# Scikit-Learn Pipelines: A Complete Guide\n",
    "\n",
    "## **Why Use a Pipeline?**\n",
    "A `Pipeline` in Scikit-Learn is useful for chaining multiple preprocessing steps and an estimator into one object. This ensures that:\n",
    "- Data transformations are **applied consistently** to both training and test sets.\n",
    "- **Data leakage** is prevented by ensuring transformations (e.g., imputation) are learned only from `X_train` and then applied to `X_test`.\n",
    "- Code is **cleaner and more maintainable**.\n",
    "\n",
    "## **How a Pipeline Works Internally**\n",
    "A pipeline consists of **transformers** (like `SimpleImputer`, `StandardScaler`) and an **estimator** (like `LogisticRegression`, `RandomForestClassifier`).\n",
    "\n",
    "### **What Happens When You Call `pipeline.fit(X_train, y_train)`?**\n",
    "1. **Transformers (like `SimpleImputer`)**:\n",
    "   - `fit(X_train)`: Learns parameters (e.g., mean for missing values).\n",
    "   - `transform(X_train)`: Applies transformations (e.g., fills missing values).\n",
    "2. **Estimator (like `LogisticRegression`)**:\n",
    "   - `fit(X_train_transformed, y_train)`: Trains the model using the transformed `X_train`.\n",
    "\n",
    "### **What Happens When You Call `pipeline.predict(X_test)`?**\n",
    "1. **Transformers (like `SimpleImputer`)**:\n",
    "   - `transform(X_test)`: Uses **previously learned** parameters (e.g., mean from `X_train`) to transform `X_test`.\n",
    "   - üö® **No `fit()` is called here**, ensuring `X_test` is not used to compute new transformation parameters.\n",
    "2. **Estimator (like `LogisticRegression`)**:\n",
    "   - `predict(X_test_transformed)`: Uses the trained model to make predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Pipeline vs. Manual Preprocessing**\n",
    "### **Manual Preprocessing (Without a Pipeline)**\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample Data\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, np.nan, 35, 40, np.nan, 50],\n",
    "    'salary': [50000, 54000, 62000, 70000, 67000, np.nan],\n",
    "    'purchased': [0, 1, 0, 1, 1, 0]\n",
    "})\n",
    "X = data[['age', 'salary']]\n",
    "y = data['purchased']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Manual Imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)  # Fit on X_train\n",
    "X_test_imputed = imputer.transform(X_test)  # Transform X_test (no fit!)\n",
    "\n",
    "# Train Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "predictions = model.predict(X_test_imputed)\n",
    "print(predictions)\n",
    "```\n",
    "‚úÖ **We must manually call `.transform(X_test)`, ensuring we don‚Äôt fit again on `X_test`.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Using a Pipeline (Automated Preprocessing & Prediction)**\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipeline.fit(X_train, y_train)  # Imputer and model fit together\n",
    "\n",
    "# Predict using pipeline\n",
    "predictions = pipeline.predict(X_test)  # X_test is automatically imputed before prediction\n",
    "print(predictions)\n",
    "```\n",
    "‚úÖ **Pipeline automatically applies the same transformations to `X_test` without manual intervention.**\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "‚úîÔ∏è `fit(X_train, y_train)`:\n",
    "- Applies `fit_transform(X_train)` for transformers.\n",
    "- Trains the estimator using transformed `X_train`.\n",
    "\n",
    "‚úîÔ∏è `predict(X_test)`:\n",
    "- Applies `transform(X_test)` using parameters learned from `X_train`.\n",
    "- Uses the trained model to predict.\n",
    "\n",
    "‚úîÔ∏è **Using a pipeline prevents data leakage and keeps the workflow clean and reproducible.**\n",
    "\n",
    "\n",
    "\n",
    "**Why we dont fit on the X-Test?:**\n",
    "\n",
    "1. SimpleImputer(strategy='mean') learns the mean of each column during .fit().\n",
    "\n",
    "2. This mean is computed only from X_train and is then reused for imputing missing values in both X_train and X_test.\n",
    "\n",
    "If you do .fit() on X_test, you're \"cheating\" ‚Äî you're letting your model see part of the test data during training, which breaks the idea of testing on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4ea34-7d79-4d42-a62f-2ad1ef48971a",
   "metadata": {},
   "source": [
    "# ColumnTransformer and Its Connection to Pipelines\r\n",
    "\r\n",
    "## **Why Use a ColumnTransformer?**\r\n",
    "A `ColumnTransformer` is used when different preprocessing steps need to be applied to different columns in a dataset. Without it, a `Pipeline` applies the same transformations to all columns, which is problematic when dealing with mixed data types (e.g., numerical and categorical features).\r\n",
    "\r\n",
    "### **Key Benefits:**\r\n",
    "- **Handle different feature types separately** (e.g., impute and scale numerical data, one-hot encode categorical data).\r\n",
    "- **Prevents data leakage** by ensuring transformations learned from `X_train` are correctly applied to `X_test`.\r\n",
    "- **Keeps preprocessing structured** and avoids errors from applying incorrect transformations to certain columns.\r\n",
    "\r\n",
    "## **How ColumnTransformer Works Inside a Pipeline**\r\n",
    "When a `ColumnTransformer` is included in a `Pipeline`, the flow works as follows:\r\n",
    "1. **During `pipeline.fit(X_train, y_train)`**:\r\n",
    "   - The `ColumnTransformer` applies `fit_transform(X_train)` to learn transformations for each column type.\r\n",
    "   - The transformed `X_train` is then passed to the estimator (e.g., `LogisticRegression.fit()`).\r\n",
    "\r\n",
    "2. **During `pipeline.predict(X_test)`**:\r\n",
    "   - The `ColumnTransformer` applies `transform(X_test)` (without refitting).\r\n",
    "   - The transformed `X_test` is then used for predictions.\r\n",
    "\r\n",
    "## **Comparison: With and Without ColumnTransformer**\r\n",
    "### **üö® Without ColumnTransformer (Incorrect Handling of Mixed Data)**\r\n",
    "```python\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Sample Data\r\n",
    "data = pd.DataFrame({\r\n",
    "    'age': [25, None, 35, 40, None, 50],\r\n",
    "    'salary': [50000, 54000, 62000, 70000, 67000, None],\r\n",
    "    'gender': ['M', 'F', 'F', 'M', 'M', 'F'],\r\n",
    "    'purchased': [0, 1, 0, 1, 1, 0]\r\n",
    "})\r\n",
    "\r\n",
    "X = data[['age', 'salary', 'gender']]\r\n",
    "y = data['purchased']\r\n",
    "\r\n",
    "pipeline = Pipeline([\r\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\r\n",
    "    ('scaler', StandardScaler()),\r\n",
    "    ('classifier', LogisticRegression())\r\n",
    "])\r\n",
    "\r\n",
    "# This will fail because we are trying to scale a categorical column\r\n",
    "pipeline.fit(X, y)\r\n",
    "```\r\n",
    "üö® **Issue**: `SimpleImputer` and `StandardScaler` are applied to all columns, causing an error when trying to scale `'gender'`.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **‚úÖ Correct Approach: Using ColumnTransformer in a Pipeline**\r\n",
    "```python\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# Define preprocessing for numerical and categorical columns\r\n",
    "preprocessor = ColumnTransformer([\r\n",
    "    ('num', Pipeline([\r\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\r\n",
    "        ('scaler', StandardScaler())\r\n",
    "    ]), ['age', 'salary']),  # Applies to numeric columns\r\n",
    "\r\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['gender'])  # Applies to categorical columns\r\n",
    "])\r\n",
    "\r\n",
    "# Full pipeline with preprocessing and model\r\n",
    "pipeline = Pipeline([\r\n",
    "    ('preprocessor', preprocessor),\r\n",
    "    ('classifier', LogisticRegression())\r\n",
    "])\r\n",
    "\r\n",
    "# Split the data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "# Fit on training data\r\n",
    "pipeline.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Predict on test data (Only calls transform, no fit_transform!)\r\n",
    "predictions = pipeline.predict(X_test)\r\n",
    "print(predictions)\r\n",
    "```\r\n",
    "‚úÖ **Fix**: Now, numerical and categorical columns are preprocessed separately before training, avoiding errors.\r\n",
    "\r\n",
    "## **Key Takeaways**\r\n",
    "‚úîÔ∏è Use `Pipeline` **alone** only when all columns undergo the same transformation.\r\n",
    "‚úîÔ∏è Use `ColumnTransformer` **inside a Pipeline** when different transformations are needed for different column types.\r\n",
    "‚úîÔ∏è `pipeline.fit(X_train, y_train)` ‚Üí Calls `fit_transform(X_train)` on transformers and trains the model.\r\n",
    "‚úîÔ∏è `pipeline.predict(X_test)` ‚Üí Calls `transform(X_test)`, ensuring consistent preprocessing without refitting.\r\n",
    "‚úîÔ∏è **Always split your data** before calling `.fit()` to prevent data leakage.\r\n",
    "\r\n",
    "This ensures that preprocessing and model training are done efficiently and correctly. üöÄ\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fe187-35b9-4b79-93a0-f5c6f224cc97",
   "metadata": {},
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7714c0-4b4b-4227-884c-4b3c6dd9ec96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
