# What Is Record Linkage?

Record Linkage is the process of finding records in different data sources that refer to the same entity — like people, places, or businesses.

Imagine two census DataFrames from different regions or years. The problem is:

- They don’t have unique IDs.
- Some entries are duplicates or slightly different (like typos or abbreviations).

So, we can't just do a `merge()` — we need fuzzy matching, and that's where the recordlinkage library comes in.

# Step-by-Step Explanation
1. Goal: Match records across two DataFrames
Suppose:

| df1        |       | df2       |       |
| ---------- | ----- | --------- | ----- |
| name       | state | name      | state |
| Alice Wong | CA    | A. Wong   | CA    |
| Bob Smith  | NY    | Robert S. | NY    |
| John Cruz  | TX    | John C.   | TX    |

We want to match "Alice Wong" with "A. Wong", "Bob Smith" with "Robert S.", etc. — even though they’re not exact matches.

2. Indexing (i.e., generating pairs)

```python
import recordlinkage

indexer = recordlinkage.Index()
indexer.block('state')  # block on 'state' to reduce comparisons
pairs = indexer.index(df1, df2)
```

What this does:

`Blocks`: Only compares rows from df1 and df2 where the state matches (so it avoids comparing CA with NY).

`Returns`: A pandas MultiIndex — like `[(0, 0), (1, 1), (2, 2)]` — where:

`First index` = row index in df1

`Second index` = row index in df2

3. Compare the Pairs
```python
compare_obj = recordlinkage.Compare()

compare_obj.exact('state', 'state', label='state')
compare_obj.string('name', 'name', threshold=0.85, label='name')
```
What this does:
- You define which columns to compare and how:

    - `.exact()` checks for exact matches

    - `.string()` does fuzzy string matching (Levenshtein distance, Jaro-Winkler, etc.)

    - `threshold=0.85` means: consider as a match if similarity ≥ 85%

- You assign labels like 'name' or 'state' for result columns.

Then:
```python
features = compare_obj.compute(pairs, df1, df2)
```
The output will be like:

| df1\_index | df2\_index | state | name |
| ---------- | ---------- | ----- | ---- |
| 0          | 0          | 1     | 1    |
| 1          | 1          | 1     | 0.9  |
| 2          | 2          | 1     | 0.88 |

Where each row = a comparison between a pair.
- A value of 1 means exact match
- Values < 1 in string columns mean partial match

4. Decide on Final Matches
You can define a rule like:

```python
matches = features[features.sum(axis=1) > 1.5]
```

That means:

- If the total match score is above 1.5, we consider them a match.

# How to decide on Threshold

| Threshold Type        | Typical Value | Use When                                  |
| --------------------- | ------------- | ----------------------------------------- |
| `.string()` threshold | 0.85–0.95     | For fuzzy match in names, cities, etc.    |
| `features.sum() > X`  | 1.5–2.0       | For combining multiple match scores       |
| Auto-tuned            | Dynamic       | If you use machine learning-based linkage |

# Linking DataFrames
1. The first step in linking dataframes is to isolate the potentially matching pairs to the one's we're pretty sure of, we know how to do that with:
`potential_matches[potential_matches.sum(axis = 1) >= n]`

2. The next step is extracting one of the index column to and use it to subset it's associated dataframes
```python
dup_rows = matches.index.get_level_values(1)
```

3. Get the non-duplicates in this dataframe because that is what you want to concatenate with the other dataframe:
```python
df2_wo_dup = df2[~df2.index.isin(dup_rows)]
complete = pd.concat(df1, df2_wo_dup)
```
