{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ba26bc-878b-425e-ba4f-c3cfaf70dd7a",
   "metadata": {},
   "source": [
    "# Importing Data From the Web\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b074963-cbce-4c2d-942a-3b55eb00ce5c",
   "metadata": {},
   "source": [
    "You can import data from the web by different ways including scraping, or simply downloading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd18aa-963b-42ac-8094-52b3fa8e2995",
   "metadata": {},
   "source": [
    "## Importing Using `urlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4f731-d08c-4d62-816d-67722e196a7a",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "| Functions | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `urlretrieve` | Downloads a file from a URL. | `urllib.request.urlretrieve(url, filename)` |\n",
    "| `urlopen` | Opens a URL for reading. | `urllib.request.urlopen(url)` |\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "| Arguments | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `url` | The URL of the file to download or open. | `urllib.request.urlretrieve(url, ...)` or `urllib.request.urlopen(url)` |\n",
    "| `filename` | The filename to save the downloaded file as. | `urllib.request.urlretrieve(..., filename)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04283fb4-5adb-4da9-97c7-19acc1f3f11e",
   "metadata": {},
   "source": [
    "**IF** you want to just load the csv into a dataframe and not save it locally, you can do that just using the `pd.read_csv()` having the url as its first argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1428c0-8184-4b92-b42d-04cce80585ec",
   "metadata": {},
   "source": [
    "## Using HTTP Request (GET) to Get Data From the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd304c-0900-4be2-84f3-3dc64a88597c",
   "metadata": {},
   "source": [
    "Let's say we want to get the HTMl file in a website, to do that we should ask for its consent by requesting GET. The following functions from two packages can be used to request:\n",
    "\n",
    "**urllib Functions**\n",
    "\n",
    "| Functions | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `Request` | Creates a request object. | `urllib.request.Request(url)` |\n",
    "| `urlopen` | Opens a URL and returns a response object. | `urllib.request.urlopen(request)` |\n",
    "| `read` | Reads the contents of a response object. | `response.read()` |\n",
    "\n",
    "**DO NOT FORGET TO CLOSE THE RESPONSE**\n",
    "\n",
    "**urllib Arguments**\n",
    "\n",
    "| Arguments | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `url` | The URL to send the request to. | `urllib.request.Request(url)` |\n",
    "| `request` | The request object. | `urllib.request.urlopen(request)` |\n",
    "\n",
    "**EXAMPLE:**\n",
    "```python\n",
    "from urllib.request import urlopen, Request\n",
    "url = 'some url'\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "html = response.read()\n",
    "response.close()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837a98f-5357-43fd-9d1a-b168e7038e07",
   "metadata": {},
   "source": [
    "**requests Functions**\n",
    "\n",
    "| Functions | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `requests.get` | Sends a GET request and returns a response object. | `requests.get(url)` |\n",
    "| `text` | Returns the content of the response, in unicode. | `response.text` |\n",
    "\n",
    "**requests Arguments**\n",
    "\n",
    "| Arguments | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `url` | The URL to send the request to. | `requests.get(url)` |\n",
    "\n",
    "**EXAMPLE:**\n",
    "```python\n",
    "import requests\n",
    "url = 'some url'\n",
    "r = request.get(url)\n",
    "text = r.text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425b51f-b3ed-4156-a1a5-400e90249c17",
   "metadata": {},
   "source": [
    "## Scraping The Web with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35cd5c-38d9-426f-9e3d-12c3daee0aff",
   "metadata": {},
   "source": [
    "Usually beautifulsoup's flow is:\n",
    "- use requests\n",
    "- use beautifulsoup\n",
    "\n",
    "Example:\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'someurl.com'\n",
    "r = requests.get(url)\n",
    "\n",
    "html_doc = r.text\n",
    "\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "html_pretty = soup.prettify()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a965a9-f1ab-4af5-a99b-dce78fa0571b",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "| Functions | Description | Syntax |\n",
    "|---|---|---|\n",
    "| `BeautifulSoup` | Creates a BeautifulSoup object from HTML or XML. | `BeautifulSoup(html_content, parser)` |\n",
    "| `prettify` | Formats the HTML into a more readable structure. | `soup.prettify()` |\n",
    "| `title` | Extracts the title tag from the HTML. | `soup.title` |\n",
    "| `get_text` | Extracts the text content from the HTML. | `soup.get_text()` |\n",
    "| `find_all` | Finds all elements matching a specified tag or criteria. | `soup.find_all(tag)` |\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "| Arguments | Description | Syntax | Example Values |\n",
    "|---|---|---|---|\n",
    "| `html_content` | The HTML or XML string to parse. | `BeautifulSoup(html_content, ...)` | A string containing HTML or XML code. |\n",
    "| `parser` | The parser to use (e.g., 'html.parser', 'lxml', 'xml'). | `BeautifulSoup(..., parser)` | `'html.parser'`, `'lxml'`, `'xml'`, `'html5lib'` |\n",
    "| `tag` | The HTML tag to search for. | `soup.find_all(tag)` | `'a'`, `'p'`, `'div'`, `'h1'`, etc. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7fccf-124a-4e7a-afa4-11919ba0d01d",
   "metadata": {},
   "source": [
    "## Working with JSON\n",
    "When working with JSON package, you assume that you will encounter a JSON File, now that being a file you must do the right way of opening a file, reading, and whatnot.\n",
    "\n",
    "```python\n",
    "import json\n",
    "with open('fileName.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# use the data\n",
    "print(type(json_data))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe7901-2c76-47ac-8997-0afe340b660c",
   "metadata": {},
   "source": [
    "## Working with API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e2f9b-1d87-40bd-8cb0-394d5fcb9559",
   "metadata": {},
   "source": [
    "What is it:\n",
    "- A bunch of code that allows programs to communicate with each other\n",
    "- Set of protocols and routines that are prolly wirtten in codes\n",
    "- If you for example are expecting a `JSON`, after you get the data it is a string, you will need to use the `json.loads(string_json)` to make it a dictionary and be able to work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841eca3f-a9bc-4534-9dae-e10231ca09f0",
   "metadata": {},
   "source": [
    "For example, if you want to connect to an API of the OMDB website, which offers the `JSON` data for movies you could do it like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd3b5e-ed13-4bae-9beb-1f12df65b373",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# The url here may seem odd but this can be seen from the documentation of the website\n",
    "url = 'http://www.omdbapi.com/?t=hackers'\n",
    "r = requests.get(url)\n",
    "json_data = r.json() # this is awesome\n",
    "\n",
    "for key, value in json_data.items():\n",
    "    print(\"key: \" + key + \" value: \" + value)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78004dc4-c107-4803-92ef-72d7977d5cd5",
   "metadata": {},
   "source": [
    "## Streaming Data from Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3577e0cf-7834-4a41-bf9b-086c928da1bb",
   "metadata": {},
   "source": [
    "Twitter uses REST API and when you are working with usually the flow is:\n",
    "- import `tweepy`, `json`\n",
    "- store your authentication\n",
    "- Create a stream object which will contain methods for you to work with Stream API\n",
    "- Gather data\n",
    "\n",
    "```python\n",
    "# Step 1\n",
    "import tweepy, json\n",
    "\n",
    "# Step 2\n",
    "access_token = '...'\n",
    "access_token_secret = '...'\n",
    "consumer_key = '...'\n",
    "consumer_secret = '...'\n",
    "\n",
    "# Step 3\n",
    "stream = tweepy.Stream(consumer_key, consumer_secret,\\\n",
    "                      access_token, accesss_token_secret)\n",
    "\n",
    "# Step 4 (filters twitter streams to capture data by keywords\n",
    "stream.filter(track = ['apples', 'oranges'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286215a4-189b-49ec-9aae-4a89d8bf3c89",
   "metadata": {},
   "source": [
    "This is an example workflow:\n",
    "```python\n",
    "# Import package\n",
    "import json\n",
    "\n",
    "# We imagine that we are able to get the json strings and put it \n",
    "# inside the text file\n",
    "tweets_data_path = 'tweets.txt'\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data = [] # we want to store the dictionaries/JSON in here\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# print(tweets_file.read())\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line) # transforms the str JSON to a dict\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())\n",
    "\n",
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text', 'lang']) # this is interesting, apparently you can pass multiple dictionaries to a dataframe\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d1f1c-6e33-4c77-8293-155d995b9beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
